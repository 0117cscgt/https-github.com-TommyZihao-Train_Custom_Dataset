{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb9285f7-5a2a-49bf-b091-fe5f00f7f741",
   "metadata": {},
   "source": [
    "# 基于DFF的图像子区域可解释性分析\n",
    "\n",
    "同济子豪兄 https://space.bilibili.com/1900783\n",
    "\n",
    "代码运行云GPU平台：https://featurize.cn/?s=d7ce99f842414bfcaea5662a97581bd1\n",
    "\n",
    "2022-9-19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaf20d6-0c53-49ee-94c0-655ad2174e0e",
   "metadata": {},
   "source": [
    "## 参考阅读\n",
    "\n",
    "代码库 pytorch-grad-cam：https://github.com/jacobgil/pytorch-grad-cam\n",
    "\n",
    "博客 Deep Feature Factorizations for better model explainability：https://jacobgil.github.io/pytorch-gradcam-book/Deep%20Feature%20Factorizations.html\n",
    "\n",
    "论文 Deep Feature Factorization For Concept Discovery：https://arxiv.org/abs/1806.10206"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb68863-a828-4509-9531-95c44edebd00",
   "metadata": {},
   "source": [
    "## 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56bab28-9179-41d2-bebc-e2c652653c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import requests\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pytorch_grad_cam import DeepFeatureFactorization\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image, deprocess_image\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "import torch\n",
    "\n",
    "# 有 GPU 就用 GPU，没有就用 CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53186924-077a-4c7f-afbc-662028dcd526",
   "metadata": {},
   "source": [
    "## 预处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc4454d-5fb0-44af-8370-4bf3c514f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 测试集图像预处理-RCTN：缩放、裁剪、转 Tensor、归一化\n",
    "test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(\n",
    "                                         mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90a6fb3-c8ba-4548-bd31-f6748596b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_from_path(img_path):\n",
    "    '''\n",
    "    输入图像文件路径，输出 图像array、归一化图像array、预处理后的tensor\n",
    "    '''\n",
    "\n",
    "    img = np.array(Image.open(img_path))\n",
    "    rgb_img_float = np.float32(img) / 255\n",
    "    input_tensor = preprocess_image(rgb_img_float,\n",
    "                                   mean=[0.485, 0.456, 0.406],\n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "    return img, rgb_img_float, input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e938c8f6-80f9-42b8-9532-c76d08e97871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(concept_scores, top_k=2):\n",
    "    \"\"\" Create a list with the image-net category names of the top scoring categories\"\"\"\n",
    "    \n",
    "    labels = {\n",
    "        0:'Hami Melon',\n",
    "        1:'Cherry Tomatoes',\n",
    "        2:'Shanzhu',\n",
    "        3:'Bayberry',\n",
    "        4:'Grapefruit',\n",
    "        5:'Lemon',\n",
    "        6:'Longan',\n",
    "        7:'Pears',\n",
    "        8:'Coconut',\n",
    "        9:'Durian',\n",
    "        10:'Dragon Fruit',\n",
    "        11:'Kiwi',\n",
    "        12:'Pomegranate',\n",
    "        13:'Sugar orange',\n",
    "        14:'Carrots',\n",
    "        15:'Navel orange',\n",
    "        16:'Mango',\n",
    "        17:'Balsam pear',\n",
    "        18:'Apple Red',\n",
    "        19:'Apple Green',\n",
    "        20:'Strawberries',\n",
    "        21:'Litchi',\n",
    "        22:'Pineapple',\n",
    "        23:'Grape White',\n",
    "        24:'Grape Red',\n",
    "        25:'Watermelon',\n",
    "        26:'Tomato',\n",
    "        27:'Cherts',\n",
    "        28:'Banana',\n",
    "        29:'Cucumber'\n",
    "    }\n",
    "    \n",
    "    concept_categories = np.argsort(concept_scores, axis=1)[:, ::-1][:, :top_k]\n",
    "    concept_labels_topk = []\n",
    "    for concept_index in range(concept_categories.shape[0]):\n",
    "        categories = concept_categories[concept_index, :]    \n",
    "        concept_labels = []\n",
    "        for category in categories:\n",
    "            score = concept_scores[concept_index, category]\n",
    "            label = f\"{labels[category].split(',')[0]}:{score:.2f}\"\n",
    "            concept_labels.append(label)\n",
    "        concept_labels_topk.append(\"\\n\".join(concept_labels))\n",
    "    return concept_labels_topk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d8c93f-d2e8-4000-a8c6-720e938b8788",
   "metadata": {},
   "source": [
    "## 载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4927838-e2ee-4437-b5fd-519f557c33dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('checkpoint/fruit30_pytorch_20220814.pth')\n",
    "model = model.eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26f96b3-db4a-44c0-96ac-12963a7b049e",
   "metadata": {},
   "source": [
    "## 载入测试图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d4cf76-5965-46e7-839b-810cf8275a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'test_img/test_fruits.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca629cd8-db19-4b19-a4ec-229a749f95a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pil = Image.open(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd031fd1-93c0-4127-8cc0-612437e9429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724857e0-39bc-4c1c-af13-3bf680385436",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = test_transform(img_pil).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3017c8a8-ecbb-4fa0-b477-0193ccffa146",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ee882-dd2f-4e73-b356-21459e013758",
   "metadata": {},
   "source": [
    "## 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91708d70-45ea-4955-b0e4-8c46d87b2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, rgb_img_float, input_tensor = get_image_from_path(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b7b64-766d-442c-9f51-8e0b445605af",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ddda1-7513-4afc-b43d-69e6f825f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7d4f4c-4b03-4c70-9b55-079bd95b64f5",
   "metadata": {},
   "source": [
    "## 初始化DFF算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c48887-3dc1-4871-ad13-9f3b3f572cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8271cf-a251-440c-b0bc-c683f4158db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = DeepFeatureFactorization(model=model, \n",
    "                               target_layer=model.layer4, \n",
    "                               computation_on_concepts=classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c698e38-ce87-48f8-9896-470183883bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concept个数（图块颜色个数）\n",
    "n_components = 5\n",
    "\n",
    "concepts, batch_explanations, concept_outputs = dff(input_tensor, n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fae05d-dd34-44c5-9012-01253cfcd237",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c416d22-9c09-49d3-b99c-b03caa88f532",
   "metadata": {},
   "source": [
    "## 图像中每个像素对应的concept热力图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9963cdd0-00d4-4b49-8964-69554f4ef6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concept个数 x 高 x 宽\n",
    "batch_explanations[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e497711d-6d2d-4ffa-98bc-a5748d1e7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(batch_explanations[0][2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266dd582-03cd-4cd7-ab80-6486303971f2",
   "metadata": {},
   "source": [
    "## concept与类别的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430bba3e-9f89-4c60-813f-1cb7acb93c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf90d0b1-fb46-4bd9-8baf-f445ba994f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_outputs = torch.softmax(torch.from_numpy(concept_outputs), axis=-1).numpy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad1219e-464e-4070-a9af-9ccc0ecdee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667cddde-d1d6-47f2-9f1d-5ac09843d3e8",
   "metadata": {},
   "source": [
    "## 每个concept展示前top_k个类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed627d53-1886-4799-b6fa-38e8809ee935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每个概念展示几个类别\n",
    "top_k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe21d98-6672-4920-96c1-c85997f2000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_label_strings = create_labels(concept_outputs, top_k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537a5cf-17aa-41bb-b714-e1af8175ef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_label_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79634cad-80fe-4335-9aec-6ad6a3bd1e48",
   "metadata": {},
   "source": [
    "## 生成可视化效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc11b1-8533-49f5-b3c7-e9943c63acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam.utils.image import show_factorization_on_image\n",
    "visualization = show_factorization_on_image(rgb_img_float, \n",
    "                                            batch_explanations[0],\n",
    "                                            image_weight=0.3, # 原始图像透明度\n",
    "                                            concept_labels=concept_label_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c6e0f9-ecda-4ef3-8741-07358bb53c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.hstack((img, visualization))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c4cad3-84a9-4516-a860-a7584321f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b561f7-7c22-4c80-b522-235984fab84d",
   "metadata": {},
   "source": [
    "## 封装函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc04df80-9d70-4240-9cf6-d1a8e6abff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dff_show(img_path='test_img/cat_dog.jpg', n_components=5, top_k=2, hstack=False):\n",
    "    img, rgb_img_float, input_tensor = get_image_from_path(img_path)\n",
    "    dff = DeepFeatureFactorization(model=model, \n",
    "                                   target_layer=model.layer4, \n",
    "                                   computation_on_concepts=classifier)\n",
    "    concepts, batch_explanations, concept_outputs = dff(input_tensor, n_components)\n",
    "    concept_outputs = torch.softmax(torch.from_numpy(concept_outputs), axis=-1).numpy()\n",
    "    concept_label_strings = create_labels(concept_outputs, top_k=top_k)\n",
    "    visualization = show_factorization_on_image(rgb_img_float, \n",
    "                                                batch_explanations[0],\n",
    "                                                image_weight=0.3, # 原始图像透明度\n",
    "                                                concept_labels=concept_label_strings)\n",
    "    if hstack:\n",
    "        result = np.hstack((img, visualization))\n",
    "    else:\n",
    "        result = visualization\n",
    "    display(Image.fromarray(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3eb445-f714-45fa-8ce7-010111a60fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_show(img_path='test_img/test_草莓.jpg', hstack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa205d6-9a9c-4d72-8814-acc9cc9d8eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_show(img_path='test_img/test_火龙果.jpg', hstack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348c6f5c-a2a5-457e-a0a3-535dc8ef7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_show(img_path='test_img/test_石榴.jpg', hstack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1c7a9e-3a75-42a4-8540-9480675cd6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_show(img_path='test_img/test_bananan.jpg', hstack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a301b-11f5-4f18-b4d0-3d3e1be4646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_show(img_path='test_img/test_kiwi.jpg', hstack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e811b2-da44-4ae6-a5d9-3237cbdba40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8175e398-e26f-4e42-897f-484300e0b78c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04606506-40ad-4721-a845-2bbdef183fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
